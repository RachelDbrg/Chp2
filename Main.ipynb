{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "28990aa5",
   "metadata": {},
   "source": [
    "## Describe the current simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2fcafb39",
   "metadata": {},
   "outputs": [],
   "source": [
    "simulation_description = \"H2V2P - test avec V2 diminue de moitie\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dba25223",
   "metadata": {},
   "source": [
    "## Import initial parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "63037557-1377-48e1-a24e-8d0a45bac4d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from spatial_parms import initialize_spatial_parms\n",
    "from parameters_animals import initialize_animal_parms\n",
    "from parameters_vegetation import initialize_veg_parms\n",
    "from initial_distribution import initial_sp_distribution\n",
    "from Diffusion_parameters import initialize_diffusion_parms\n",
    "from diffusion_seasons import seasonal_eta_H1, seasonal_sigma_H1\n",
    "from intermediate import log_intermediates\n",
    "\n",
    "Nx, Ny, dx, dy, dt, Nt, Lx, Ly = initialize_spatial_parms()\n",
    "V2_croiss, V1_croiss, k_V2_val, k_V1_norm, k_V2_max = initialize_veg_parms()\n",
    "V1, V2, H1, H2, P, k_V1, k_V2, mask_V2, mask_V1 = initial_sp_distribution(Nx, Ny, k_V1_norm, k_V2_max)\n",
    "rho_H1, a_H2, a_H1, h_V2H2, e_V1, e_V2, h_V1H1, h_V2H1, h_V1H2, mu_H2, mu_H1, epsi_AJ, chi_H2, chi_H1, a_PH2, a_PH1, h_PH1, h_PH2, mu_P, phi_P, h_P, chi_P, epsi_H1H2, gamma_H1H2, I_H1, I_H2 = initialize_animal_parms(k_V2_max, k_V1_norm, k_V2_max)\n",
    "sigma_H1, sigma_H2, sigma_P, eta_H1, eta_H2, eta_P, alpha_H2H2, alpha_H1H1, alpha_PP, alpha_H2V1, alpha_H2V2, alpha_H1V2, alpha_H1V1, alpha_PH2, alpha_PH1 = initialize_diffusion_parms()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abaee3b9",
   "metadata": {},
   "source": [
    "## Save metadata associated with the simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9906a8a0",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Object of type function is not JSON serializable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 43\u001b[0m\n\u001b[1;32m     40\u001b[0m sim_settings \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNt\u001b[39m\u001b[38;5;124m\"\u001b[39m: Nt, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mt_span\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mlist\u001b[39m(t_span), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msolver\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLSODA\u001b[39m\u001b[38;5;124m\"\u001b[39m}\n\u001b[1;32m     41\u001b[0m notes \u001b[38;5;241m=\u001b[39m simulation_description\n\u001b[0;32m---> 43\u001b[0m metadata_path \u001b[38;5;241m=\u001b[39m \u001b[43msave_metadata\u001b[49m\u001b[43m(\u001b[49m\u001b[43mactive_species\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msim_settings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimestamp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnotes\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/RAD/Chp2/log_metadata.py:23\u001b[0m, in \u001b[0;36msave_metadata\u001b[0;34m(species, params, grid, sim_settings, timestamp, notes)\u001b[0m\n\u001b[1;32m     20\u001b[0m filepath \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(config_dir, filename)\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(filepath, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m---> 23\u001b[0m     \u001b[43mjson\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdump\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m filepath\n",
      "File \u001b[0;32m/usr/lib64/python3.12/json/__init__.py:179\u001b[0m, in \u001b[0;36mdump\u001b[0;34m(obj, fp, skipkeys, ensure_ascii, check_circular, allow_nan, cls, indent, separators, default, sort_keys, **kw)\u001b[0m\n\u001b[1;32m    173\u001b[0m     iterable \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m(skipkeys\u001b[38;5;241m=\u001b[39mskipkeys, ensure_ascii\u001b[38;5;241m=\u001b[39mensure_ascii,\n\u001b[1;32m    174\u001b[0m         check_circular\u001b[38;5;241m=\u001b[39mcheck_circular, allow_nan\u001b[38;5;241m=\u001b[39mallow_nan, indent\u001b[38;5;241m=\u001b[39mindent,\n\u001b[1;32m    175\u001b[0m         separators\u001b[38;5;241m=\u001b[39mseparators,\n\u001b[1;32m    176\u001b[0m         default\u001b[38;5;241m=\u001b[39mdefault, sort_keys\u001b[38;5;241m=\u001b[39msort_keys, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw)\u001b[38;5;241m.\u001b[39miterencode(obj)\n\u001b[1;32m    177\u001b[0m \u001b[38;5;66;03m# could accelerate with writelines in some versions of Python, at\u001b[39;00m\n\u001b[1;32m    178\u001b[0m \u001b[38;5;66;03m# a debuggability cost\u001b[39;00m\n\u001b[0;32m--> 179\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m    180\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/lib64/python3.12/json/encoder.py:432\u001b[0m, in \u001b[0;36m_make_iterencode.<locals>._iterencode\u001b[0;34m(o, _current_indent_level)\u001b[0m\n\u001b[1;32m    430\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m _iterencode_list(o, _current_indent_level)\n\u001b[1;32m    431\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(o, \u001b[38;5;28mdict\u001b[39m):\n\u001b[0;32m--> 432\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m _iterencode_dict(o, _current_indent_level)\n\u001b[1;32m    433\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    434\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m markers \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/usr/lib64/python3.12/json/encoder.py:406\u001b[0m, in \u001b[0;36m_make_iterencode.<locals>._iterencode_dict\u001b[0;34m(dct, _current_indent_level)\u001b[0m\n\u001b[1;32m    404\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    405\u001b[0m             chunks \u001b[38;5;241m=\u001b[39m _iterencode(value, _current_indent_level)\n\u001b[0;32m--> 406\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m chunks\n\u001b[1;32m    407\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m newline_indent \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    408\u001b[0m     _current_indent_level \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m/usr/lib64/python3.12/json/encoder.py:406\u001b[0m, in \u001b[0;36m_make_iterencode.<locals>._iterencode_dict\u001b[0;34m(dct, _current_indent_level)\u001b[0m\n\u001b[1;32m    404\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    405\u001b[0m             chunks \u001b[38;5;241m=\u001b[39m _iterencode(value, _current_indent_level)\n\u001b[0;32m--> 406\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m chunks\n\u001b[1;32m    407\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m newline_indent \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    408\u001b[0m     _current_indent_level \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m/usr/lib64/python3.12/json/encoder.py:439\u001b[0m, in \u001b[0;36m_make_iterencode.<locals>._iterencode\u001b[0;34m(o, _current_indent_level)\u001b[0m\n\u001b[1;32m    437\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCircular reference detected\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    438\u001b[0m     markers[markerid] \u001b[38;5;241m=\u001b[39m o\n\u001b[0;32m--> 439\u001b[0m o \u001b[38;5;241m=\u001b[39m \u001b[43m_default\u001b[49m\u001b[43m(\u001b[49m\u001b[43mo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    440\u001b[0m \u001b[38;5;28;01myield from\u001b[39;00m _iterencode(o, _current_indent_level)\n\u001b[1;32m    441\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m markers \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/usr/lib64/python3.12/json/encoder.py:180\u001b[0m, in \u001b[0;36mJSONEncoder.default\u001b[0;34m(self, o)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdefault\u001b[39m(\u001b[38;5;28mself\u001b[39m, o):\n\u001b[1;32m    162\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Implement this method in a subclass such that it returns\u001b[39;00m\n\u001b[1;32m    163\u001b[0m \u001b[38;5;124;03m    a serializable object for ``o``, or calls the base implementation\u001b[39;00m\n\u001b[1;32m    164\u001b[0m \u001b[38;5;124;03m    (to raise a ``TypeError``).\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    178\u001b[0m \n\u001b[1;32m    179\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 180\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mObject of type \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mo\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    181\u001b[0m                     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mis not JSON serializable\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: Object of type function is not JSON serializable"
     ]
    }
   ],
   "source": [
    "from log_metadata import save_metadata\n",
    "from datetime import datetime\n",
    "\n",
    "timestamp = datetime.now().strftime(\"%Y-%m-%d_%H-%M\")\n",
    "\n",
    "# Duration of the simulations\n",
    "t_span = (0, dt * Nt)\n",
    "\n",
    "# Present species\n",
    "species = {\"V1\": V1, \"V2\": V2, \"H1\": H1, \"H2\": H2, \"P\": P}\n",
    "active_species = [name for name, field in species.items() if np.any(field != 0)]\n",
    "\n",
    "# Parameters we want to track\n",
    "params = {\n",
    "    \"alpha_H1V1\": alpha_H1V1,\n",
    "    \"alpha_H1V2\": alpha_H1V2,\n",
    "    \"alpha_H2V2\": alpha_H2V2,\n",
    "    \"alpha_H2V1\": alpha_H1V1,\n",
    "\n",
    "    \"alpha_H2H2\": alpha_H2H2,\n",
    "    \"alpha_H1H1\": alpha_H1H1,\n",
    "    \n",
    "    \"eta_H1\": eta_H1,\n",
    "    \"eta_H2\": eta_H1,\n",
    "    \"eta_P\": eta_P,\n",
    "\n",
    "    \"sigma_H1\": sigma_H1,\n",
    "    \"sigma_H2\": sigma_H2,\n",
    "    \"sigma_P\": sigma_P,\n",
    "\n",
    "    \"alpha_PH2\": alpha_PH2,\n",
    "    \"alpha_PH1\": alpha_PH1,\n",
    "\n",
    "    'eta_H1_fn': seasonal_eta_H1,\n",
    "    'sigma_H1_fn': seasonal_sigma_H1\n",
    "}\n",
    "\n",
    "\n",
    "grid = {\"Nx\": Nx, \"Ny\": Ny, \"dx\": dx, \"dy\": dy}\n",
    "sim_settings = {\"Nt\": Nt, \"t_span\": list(t_span), \"solver\": \"LSODA\"}\n",
    "notes = simulation_description\n",
    "\n",
    "metadata_path = save_metadata(active_species, params, grid, sim_settings, timestamp, notes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fc1f35f",
   "metadata": {},
   "source": [
    "## Define landscape barrier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "234b2ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Landscape_disturbances_mask import create_barrier_mask\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "barrier_mask = create_barrier_mask((Nx, Ny), orientation='vertical', thickness=0, position='center')\n",
    "# Put thickness to 0 to get ride of the barrier\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e76c5ab5",
   "metadata": {},
   "source": [
    "## Plot the initial distribution of species, carrying capacities and barrier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "217f768a-751d-45a3-9017-f4688e241a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from plot_distribution import plot_species_distribution\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "# Base folder for all time series plots\n",
    "plot_dir = os.path.join(\"outputs\", timestamp, \"initial_distribution\")\n",
    "os.makedirs(plot_dir, exist_ok=True) # Make sure the folder exist, otherwise, gets created\n",
    "\n",
    "t_idx = 0\n",
    "\n",
    "V1_t = V1[:, :]\n",
    "V2_t = V2[:, :]\n",
    "H1_t = H1[:, :]\n",
    "H2_t = H2[:, :]\n",
    "P_t  = P[:, :]\n",
    "barrier_mask  = barrier_mask[:, :]\n",
    "k_V2  = k_V2[:, :]\n",
    "k_V1  = k_V1[:, :]\n",
    "\n",
    "species_fields = { \n",
    "    \"Deciduous\": V2_t,\n",
    "    \"Lichen\": V1_t,\n",
    "    \"Caribou\": H1_t,\n",
    "    \"Moose\": H2_t,\n",
    "    \"Predator\": P_t,\n",
    "    \"Barrier\": barrier_mask,\n",
    "    \"k_V2\": k_V2,\n",
    "    \"k_V1\": k_V1\n",
    "}\n",
    "\n",
    "\n",
    "for species_name, field in species_fields.items():\n",
    "    if np.any(field != 0):\n",
    "        filename = os.path.join(plot_dir, f\"{species_name}.png\")\n",
    "        plot_species_distribution(field, Lx, Ly, species_name=species_name, save_path=filename, time_label= t_idx)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f622d28",
   "metadata": {},
   "source": [
    "## Plot the patches scores for herbivores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff8b4b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from compute_score_maps import compute_norm_score_patch\n",
    "\n",
    "# Base folder for all time series plots\n",
    "score_dir = os.path.join(\"outputs\", timestamp, \"score_maps\")\n",
    "os.makedirs(score_dir, exist_ok=True) # Make sure the folder exist, otherwise, gets created\n",
    "\n",
    "# Compute score for the herbivore H2\n",
    "score_G_H2, norm_score_G_H2 = compute_norm_score_patch(\n",
    "    alpha_H2H2, H2,\n",
    "    alpha_H2V1, V1,\n",
    "    alpha_H2V2, V2,\n",
    "    alpha_PH2, P\n",
    ")\n",
    "\n",
    "# Compute score for the herbivore H1\n",
    "score_G_H1, norm_score_G_H1 = compute_norm_score_patch(\n",
    "    alpha_H1H1, H1,\n",
    "    alpha_H1V1, V1,\n",
    "    alpha_H1V2, V2,\n",
    "    alpha_PH2, P\n",
    ")\n",
    "\n",
    "# Compute score for the predator P\n",
    "score_G_P, norm_score_G_P = compute_norm_score_patch(\n",
    "    alpha_PP, P,\n",
    "    alpha_PH1, H1,\n",
    "    alpha_PH2, H2,\n",
    "    0, 0\n",
    ")\n",
    "\n",
    "fields_to_plot = {\n",
    "    \"V1_distribution\": V1,\n",
    "    \"V2_distribution\": V2,\n",
    "    \"H1_distribution\": H1,\n",
    "    \"H2_distribution\": H2,\n",
    "    \"G_H2_raw\": score_G_H2,\n",
    "    \"G_H1_raw\": score_G_H1,\n",
    "    \"G_P_raw\": score_G_P,\n",
    "    \"G_H2_normalized\": norm_score_G_H2,\n",
    "    \"G_H1_normalized\": norm_score_G_H1,\n",
    "    \"G_P_normalized\": norm_score_G_P\n",
    "}\n",
    "\n",
    "colormaps = {\n",
    "    \"V1_distribution\": \"viridis\",\n",
    "    \"V2_distribution\": \"viridis\",\n",
    "    \"H1_distribution\": \"viridis\",\n",
    "    \"H2_distribution\": \"viridis\",\n",
    "    \"G_H2_raw\": \"viridis\",\n",
    "    \"G_H1_raw\": \"viridis\",\n",
    "    \"G_P_raw\": \"viridis\",\n",
    "    \"G_H2_normalized\": \"plasma\",\n",
    "    \"G_H1_normalized\": \"plasma\",\n",
    "    \"G_P_normalized\": \"plasma\"\n",
    "    \n",
    "}\n",
    "\n",
    "\n",
    "for name, field in fields_to_plot.items():\n",
    "    cmap = colormaps.get(name, \"viridis\")  # fallback to viridis\n",
    "    plt.figure()\n",
    "    plt.imshow(field, origin=\"lower\", cmap=cmap)\n",
    "    plt.colorbar(label=\"Score\")\n",
    "    plt.title(name.replace(\"_\", \" \"))\n",
    "    plt.savefig(os.path.join(score_dir, f\"{name}.png\"), bbox_inches=\"tight\", dpi=300)\n",
    "    plt.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff6c1d36",
   "metadata": {},
   "source": [
    "## Solve the PDE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5915c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.integrate import solve_ivp\n",
    "from PDE_solving import system_rhs\n",
    "import numpy as np\n",
    "from fct_flat_field import flatten_fields\n",
    "from fct_flat_field import unflatten_fields\n",
    "from intermediate import log_intermediates\n",
    "\n",
    "\n",
    "# Prep initial state\n",
    "y0 = flatten_fields(V1, V2, H1, H2, P)\n",
    "\n",
    "print(\"y0 has NaNs?\", np.any(np.isnan(y0)))\n",
    "print(\"y0 has Infs?\", np.any(np.isinf(y0)))\n",
    "print(\"y0 min/max:\", np.min(y0), np.max(y0))\n",
    "\n",
    "t_span = (0, dt * Nt)\n",
    "t_eval = np.linspace(*t_span, Nt)\n",
    "\n",
    "# Bundle parameters\n",
    "params = {\n",
    "    'V1_croiss': V1_croiss, 'V2_croiss': V2_croiss,\n",
    "    'k_V1_norm': k_V1_norm, 'k_V2_val': k_V2_val,\n",
    "    'a_H1': a_H1, 'a_H2': a_H2,\n",
    "    'h_V1H1': h_V1H1, 'h_V2H1': h_V2H1,\n",
    "    'h_V1H2': h_V1H2, 'h_V2H2': h_V2H2,\n",
    "    'rho_H1': rho_H1,\n",
    "    'h_PH1': h_PH1, 'h_PH2': h_PH2,\n",
    "    'a_PH1': a_PH1, 'a_PH2': a_PH2, \n",
    "    'chi_H1': chi_H1, 'chi_H2': chi_H2,\n",
    "    'mu_H1': mu_H1, 'mu_H2': mu_H2, \n",
    "    'e_V1': e_V1, 'e_V2': e_V2,\n",
    "    'epsi_AJ': epsi_AJ, \n",
    "    'sigma_H1': sigma_H1, 'sigma_H2': sigma_H2, 'sigma_P': sigma_P, \n",
    "    'eta_H1': eta_H1, 'eta_H2': eta_H2, 'eta_P': eta_P, \n",
    "    'alpha_H1H1': alpha_H1H1, 'alpha_H2H2': alpha_H2H2, 'alpha_PP': alpha_PP,\n",
    "    'alpha_H2V1': alpha_H2V1, 'alpha_H2V2': alpha_H2V2,\n",
    "    'alpha_H1V1': alpha_H1V1, 'alpha_H1V2': alpha_H1V2,\n",
    "    'alpha_PH1': alpha_PH1, 'alpha_PH2': alpha_PH2,\n",
    "    'mu_P': mu_P, 'phi_P': phi_P, 'h_P': h_P,\n",
    "    'chi_P': chi_P, 'epsi_H1H2': epsi_H1H2,\n",
    "    'gamma_H1H2': gamma_H1H2\n",
    "    \n",
    "}\n",
    "\n",
    "# 4. Initialize logs BEFORE defining the function\n",
    "logged_data = {\n",
    "    \"score_G_H1\": [],\n",
    "    \"Dm_eff_H1\": [],\n",
    "    \"score_G_H2\": [],\n",
    "    \"Dm_eff_H2\": [],\n",
    "    \"score_G_P\": [],\n",
    "    \"Dm_eff_P\": [],\n",
    "    \"k_H1\": [],\n",
    "    \"k_H2\": [],\n",
    "    \"safe_k_H1\": [],\n",
    "    \"safe_k_H2\": [],\n",
    "    \"safe_r_P\": [],\n",
    "    \"predation_H2\": [],\n",
    "    \"predation_H1\": [],\n",
    "    \"safe_k_V1\": [],\n",
    "    \"safe_k_V2\": []\n",
    "\n",
    "}\n",
    "\n",
    "# 5. Define the logging function\n",
    "\n",
    "# 6. Call solver and pass log function\n",
    "sol = solve_ivp(\n",
    "    fun=lambda t, y: system_rhs(\n",
    "        t, y, Nx, Ny, dx, dy, params, mask_V2, mask_V1, barrier_mask,\n",
    "        log_fn=lambda t, **fields: log_intermediates(t, logged_data, **fields)\n",
    "    ),\n",
    "    t_span=t_span,\n",
    "    y0=y0,\n",
    "    t_eval=t_eval,\n",
    "    method='LSODA'\n",
    ")\n",
    "\n",
    "\n",
    "# Save the logged files as pickles\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "# Ensure the DEBUG folder exists\n",
    "os.makedirs(\"DEBUG\", exist_ok=True)\n",
    "\n",
    "# Save the pickle file inside it\n",
    "with open(\"DEBUG/logged_data.pkl\", \"wb\") as f:\n",
    "    pickle.dump(logged_data, f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7ee2bae",
   "metadata": {},
   "source": [
    "## Transform the outputs for visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b5a9c8f-b6ff-476a-a5cb-0fefce97a8f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Number of spatial points\n",
    "N = Nx * Ny\n",
    "\n",
    "# Convert sol.y to numpy array (if not already)\n",
    "y_array = np.array(sol.y)\n",
    "\n",
    "# Reshape each species\n",
    "V1_over_time = y_array[0        : N,     :].reshape(Nx, Ny, -1)  # shape (Nx, Ny, Nt)\n",
    "V2_over_time = y_array[N        : 2*N,   :].reshape(Nx, Ny, -1)\n",
    "H1_over_time = y_array[2*N      : 3*N,   :].reshape(Nx, Ny, -1)\n",
    "H2_over_time = y_array[3*N      : 4*N,   :].reshape(Nx, Ny, -1)\n",
    "P_over_time  = y_array[4*N      : 5*N,   :].reshape(Nx, Ny, -1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36e7b700",
   "metadata": {},
   "source": [
    "## Plot the species dynamics through time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a346bfd",
   "metadata": {},
   "source": [
    "### Sum of the densities over the whole grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce0f26a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "# Base folder for all time series plots\n",
    "base_output_dir = os.path.join(\"outputs\", f\"{timestamp}\", \"global_time_series\")\n",
    "os.makedirs(base_output_dir, exist_ok=True)\n",
    "\n",
    "# Loop over species\n",
    "species_list = [\"H1\", \"H2\", \"V1\", \"V2\", \"P\"]\n",
    "for species_name in species_list:\n",
    "    \n",
    "    # Retrieve time series data\n",
    "    species_field = globals()[f\"{species_name}_over_time\"]\n",
    "    species_sum = np.sum(species_field, axis=(0, 1))\n",
    "\n",
    "    # Set parameter values\n",
    "    if species_name == \"H1\":\n",
    "        alpha_V1 = alpha_H1V1\n",
    "        alpha_V2 = alpha_H1V2\n",
    "        eta = eta_H1\n",
    "        color = \"orange\"\n",
    "    elif species_name == \"H2\":\n",
    "        alpha_V1 = alpha_H2V1\n",
    "        alpha_V2 = alpha_H2V2\n",
    "        eta = eta_H2\n",
    "        color = \"purple\"\n",
    "    elif species_name == \"V1\":\n",
    "        alpha_V1 = alpha_V2 = eta = 0.0\n",
    "        color = \"blue\"\n",
    "    elif species_name == \"V2\":\n",
    "        alpha_V1 = alpha_V2 = eta = 0.0\n",
    "        color = \"green\"\n",
    "    elif species_name == \"P\":\n",
    "        alpha_V1 = alpha_PH1\n",
    "        alpha_V2 = alpha_PH2\n",
    "        eta = eta_P\n",
    "        color = \"red\"\n",
    "    else:\n",
    "        continue\n",
    "\n",
    "    # Create and save figure\n",
    "    filename = f\"{species_name}_alphaV1_{alpha_V1:.2f}_alphaV2_{alpha_V2:.2f}_eta_{eta:.2f}.png\"\n",
    "    filepath = os.path.join(base_output_dir, filename)\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(sol.t, species_sum, label=species_name, color=color)\n",
    "    plt.xlabel(\"Time\")\n",
    "    plt.ylabel(\"Total Value (Sum over Grid)\")\n",
    "    plt.title(f\"{species_name} Dynamics Over Time\")\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(filepath)\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0962e463",
   "metadata": {},
   "source": [
    "### Mean of the densities over the whole grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "041265d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "# Base folder for all time series plots\n",
    "base_output_dir = os.path.join(\"outputs\", f\"{timestamp}\", \"mean_time_series\")\n",
    "os.makedirs(base_output_dir, exist_ok=True)\n",
    "\n",
    "# Loop over species\n",
    "species_list = [\"H1\", \"H2\", \"V1\", \"V2\", \"P\"]\n",
    "for species_name in species_list:\n",
    "    \n",
    "    # Retrieve time series data\n",
    "    species_field = globals()[f\"{species_name}_over_time\"]\n",
    "    species_sum = np.mean(species_field, axis=(0, 1))\n",
    "\n",
    "    # Set parameter values\n",
    "    if species_name == \"H1\":\n",
    "        alpha_V1 = alpha_H1V1\n",
    "        alpha_V2 = alpha_H1V2\n",
    "        eta = eta_H1\n",
    "        color = \"orange\"\n",
    "    elif species_name == \"H2\":\n",
    "        alpha_V1 = alpha_H2V1\n",
    "        alpha_V2 = alpha_H2V2\n",
    "        eta = eta_H2\n",
    "        color = \"purple\"\n",
    "    elif species_name == \"V1\":\n",
    "        alpha_V1 = alpha_V2 = eta = 0.0\n",
    "        color = \"blue\"\n",
    "    elif species_name == \"V2\":\n",
    "        alpha_V1 = alpha_V2 = eta = 0.0\n",
    "        color = \"green\"\n",
    "    elif species_name == \"P\":\n",
    "        alpha_V1 = alpha_PH1\n",
    "        alpha_V2 = alpha_PH2\n",
    "        eta = eta_P\n",
    "        color = \"red\"\n",
    "    else:\n",
    "        continue\n",
    "\n",
    "    # Create and save figure\n",
    "    filename = f\"{species_name}_alphaV1_{alpha_V1:.2f}_alphaV2_{alpha_V2:.2f}_eta_{eta:.2f}.png\"\n",
    "    filepath = os.path.join(base_output_dir, filename)\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(sol.t, species_sum, label=species_name, color=color)\n",
    "    plt.xlabel(\"Time\")\n",
    "    plt.ylabel(\"Total Value (Mean over Grid)\")\n",
    "    plt.title(f\"{species_name} Dynamics Over Time\")\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(filepath)\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c937ad35",
   "metadata": {},
   "source": [
    "## Plot of the final spatial state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8085ce09",
   "metadata": {},
   "outputs": [],
   "source": [
    "from plot_distribution import plot_species_distribution\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "# Base folder for all time series plots\n",
    "plot_dir = os.path.join(\"outputs\", timestamp, \"final_distribution\")\n",
    "os.makedirs(plot_dir, exist_ok=True) # Make sure the folder exist, otherwise, gets created\n",
    "\n",
    "max_t_idx = V2_over_time.shape[2] - 1\n",
    "t_idx = max_t_idx\n",
    "\n",
    "V1_t = V1_over_time[:, :, t_idx]\n",
    "V2_t = V2_over_time[:, :, t_idx]\n",
    "H1_t = H1_over_time[:, :, t_idx]\n",
    "H2_t = H2_over_time[:, :, t_idx]\n",
    "P_t  = P_over_time[:, :, t_idx]\n",
    "\n",
    "\n",
    "species_fields = {\n",
    "    \"Deciduous\": V2_t,\n",
    "    \"Lichen\": V1_t,\n",
    "    \"Caribou\": H1_t,\n",
    "    \"Moose\": H2_t,\n",
    "    \"Predator\": P_t,\n",
    "    \"Barrier\": barrier_mask,\n",
    "    \"k_V2\": k_V2,\n",
    "    \"k_V1\": k_V1\n",
    "}\n",
    "\n",
    "\n",
    "for species_name, field in species_fields.items():\n",
    "    if np.any(field != 0):\n",
    "        filename = os.path.join(plot_dir, f\"{species_name}.png\")\n",
    "        plot_species_distribution(field, Lx, Ly, species_name=species_name, save_path=filename, time_label= t_idx)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a735f748",
   "metadata": {},
   "source": [
    "## Dynamics through time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0f010f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Choose your species\n",
    "species_name = \"P\"\n",
    "species_field = globals()[f\"{species_name}_over_time\"]\n",
    "\n",
    "# Extract parameter values associated with the species\n",
    "if species_name == \"H1\":\n",
    "    alpha_V1 = alpha_H1V1\n",
    "    alpha_V2 = alpha_H1V2\n",
    "    eta = eta_H1\n",
    "elif species_name == \"H2\":\n",
    "    alpha_V1 = alpha_H2V1\n",
    "    alpha_V2 = alpha_H2V2\n",
    "    eta = eta_H2\n",
    "elif species_name == \"P\":\n",
    "    alpha_V1 = alpha_PH1\n",
    "    alpha_V2 = alpha_PH2\n",
    "    eta = eta_P\n",
    "else:\n",
    "    raise ValueError(f\"Unknown species: {species_name}\")\n",
    "\n",
    "# Create folder name from parameters\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "# Base folder for all time series plots\n",
    "output_dir = os.path.join(\"outputs\", f\"{timestamp}\", f\"frames_{species_name}\")\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Frame-saving function\n",
    "def save_frame(field, title, t_idx, t_eval, Lx, Ly, filename):\n",
    "    plt.imshow(field[:, :, t_idx], cmap='viridis', extent=[0, Lx, 0, Ly], origin='lower')\n",
    "    plt.colorbar()\n",
    "    plt.title(f\"{title} at time t={t_eval[t_idx]:.2f}\")\n",
    "    plt.xlabel(\"x\")\n",
    "    plt.ylabel(\"y\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(filename)\n",
    "    plt.close()\n",
    "\n",
    "# Save sampled frames\n",
    "total_frames = 50\n",
    "step = max(1, species_field.shape[2] // total_frames)\n",
    "selected_indices = list(range(0, species_field.shape[2], step))[:total_frames]\n",
    "\n",
    "for i, t_idx in enumerate(selected_indices):\n",
    "    fname = os.path.join(output_dir, f\"{species_name}_{i:04d}.png\")\n",
    "    save_frame(species_field, species_name, t_idx, t_eval, Lx, Ly, fname)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8e8b097",
   "metadata": {},
   "outputs": [],
   "source": [
    "import imageio.v2 as imageio\n",
    "import os\n",
    "\n",
    "# Match the species name and corresponding parameters\n",
    "species_name = \"P\"\n",
    "\n",
    "if species_name == \"H1\":\n",
    "    alpha_V1 = alpha_H1V1\n",
    "    alpha_V2 = alpha_H1V2\n",
    "    eta = eta_H1\n",
    "elif species_name == \"H2\":\n",
    "    alpha_V1 = alpha_H2V1\n",
    "    alpha_V2 = alpha_H2V2\n",
    "    eta = eta_H2\n",
    "elif species_name == \"P\":\n",
    "    alpha_V1 = alpha_PH1\n",
    "    alpha_V2 = alpha_PH2\n",
    "    eta = eta_P\n",
    "else:\n",
    "    raise ValueError(f\"Unknown species: {species_name}\")\n",
    "\n",
    "# Use the same parameter-aware folder as during frame generation\n",
    "\n",
    "from datetime import datetime\n",
    "output_dir = os.path.join(\"outputs\", f\"{timestamp}\", f\"frames_{species_name}\")\n",
    "\n",
    "# Output folder for GIFs\n",
    "gif_dir = os.path.join(\"outputs\", f\"{timestamp}\", \"GIF\")\n",
    "os.makedirs(gif_dir, exist_ok=True)\n",
    "\n",
    "# Number of frames and file loading\n",
    "n_frames = 50\n",
    "images = []\n",
    "for i in range(n_frames):\n",
    "    fname = os.path.join(output_dir, f\"{species_name}_{i:04d}.png\")\n",
    "    images.append(imageio.imread(fname))\n",
    "\n",
    "# Save the animation\n",
    "output_gif_path = os.path.join(gif_dir, f\"{species_name}.gif\")\n",
    "imageio.mimsave(output_gif_path, images, duration=0.2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "342382a8",
   "metadata": {},
   "source": [
    "## Display dynamics of all species currently in the system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ead1eeca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_overlay_frame(H1_field, H2_field, P_field, t_idx, t_eval, Lx, Ly, filename, barrier_mask):\n",
    "    # Create figure\n",
    "    plt.figure()\n",
    "\n",
    "    # Plot H1 and assign mappable\n",
    "    h1_plot = plt.imshow(H1_field[:, :, t_idx], cmap='Blues', alpha=0.6,\n",
    "                         extent=[0, Lx, 0, Ly], origin='lower')\n",
    "\n",
    "    # Plot H2\n",
    "    plt.imshow(H2_field[:, :, t_idx], cmap='Reds', alpha=0.6,\n",
    "               extent=[0, Lx, 0, Ly], origin='lower')\n",
    "    \n",
    "    # Plot P\n",
    "    plt.imshow(P_field[:, :, t_idx], cmap='viridis', alpha=0.6,\n",
    "               extent=[0, Lx, 0, Ly], origin='lower')\n",
    "\n",
    "    # Overlay barrier\n",
    "    plt.contour(barrier_mask, levels=[0.5], colors='black', linewidths=2,\n",
    "                extent=[0, Lx, 0, Ly])\n",
    "\n",
    "    # Plot details\n",
    "    plt.title(f\"H1, H2 and P overlay at t={t_eval[t_idx]:.2f}\")\n",
    "    plt.xlabel(\"x\")\n",
    "    plt.ylabel(\"y\")\n",
    "    plt.colorbar(h1_plot)  # Explicit mappable from H1\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(filename)\n",
    "    plt.close()\n",
    "\n",
    "# Folder for overlays\n",
    "overlay_dir = os.path.join(\"outputs\", timestamp, \"frames_overlay_H1_H2_P\")\n",
    "os.makedirs(overlay_dir, exist_ok=True)\n",
    "\n",
    "\n",
    "for i, t_idx in enumerate(selected_indices):\n",
    "    fname = os.path.join(overlay_dir, f\"H1_H2_P_overlay_{i:04d}.png\")\n",
    "    save_overlay_frame(H1_over_time, H2_over_time, P_over_time, t_idx, t_eval, Lx, Ly, fname, barrier_mask)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a9e13e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import imageio.v2 as imageio\n",
    "import os\n",
    "\n",
    "# Frame folder (overlay version)\n",
    "overlay_dir = os.path.join(\"outputs\", timestamp, \"frames_overlay_H1_H2_P\")\n",
    "gif_output_dir = os.path.join(\"outputs\", timestamp, \"GIF\")\n",
    "os.makedirs(gif_output_dir, exist_ok=True)\n",
    "\n",
    "# Assemble GIF from saved overlays\n",
    "n_frames = 50  # match total_frames from frame creation\n",
    "images = []\n",
    "for i in range(n_frames):\n",
    "    fname = os.path.join(overlay_dir, f\"H1_H2_P_overlay_{i:04d}.png\")\n",
    "    images.append(imageio.imread(fname))\n",
    "\n",
    "# Save the animation\n",
    "gif_path = os.path.join(gif_output_dir, \"H1_H2_P_overlay_animation.gif\")\n",
    "imageio.mimsave(gif_path, images, duration=0.2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4307140",
   "metadata": {},
   "source": [
    "## DEBUG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "358c9074",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the final logged carrying capacities\n",
    "_, k_H1_final = logged_data[\"k_H1\"][-1]\n",
    "_, k_H2_final = logged_data[\"k_H2\"][-1]\n",
    "\n",
    "_, safe_k_H1_final = logged_data[\"safe_k_H1\"][-1]\n",
    "_, safe_k_H2_final = logged_data[\"safe_k_H2\"][-1]\n",
    "\n",
    "_, predation_H1 = logged_data[\"predation_H1\"][-1]\n",
    "_, predation_H2 = logged_data[\"predation_H2\"][-1]\n",
    "\n",
    "_, safe_k_V1_final = logged_data[\"safe_k_V1\"][-1]\n",
    "_, safe_k_V2_final = logged_data[\"safe_k_V2\"][-1]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b44bf020",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, k_H1_initial = logged_data[\"k_H1\"][0]\n",
    "_, k_H2_initial = logged_data[\"k_H2\"][0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d5b9c4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_carrying_capacities(k_H1, k_H2, Lx, Ly, time_label=\"final\"):\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "    im1 = axes[0].imshow(safe_k_H1_final, extent=[0, Lx, 0, Ly], origin=\"lower\", cmap=\"Blues\")\n",
    "    axes[0].set_title(f\"k_H1 (H1 Carrying Capacity) at t = {time_label}\")\n",
    "    axes[0].set_xlabel(\"x\")\n",
    "    axes[0].set_ylabel(\"y\")\n",
    "    plt.colorbar(im1, ax=axes[0])\n",
    "\n",
    "    im2 = axes[1].imshow(safe_k_H2_final, extent=[0, Lx, 0, Ly], origin=\"lower\", cmap=\"Purples\")\n",
    "    axes[1].set_title(f\"k_H2 (H2 Carrying Capacity) at t = {time_label}\")\n",
    "    axes[1].set_xlabel(\"x\")\n",
    "    axes[1].set_ylabel(\"y\")\n",
    "    plt.colorbar(im2, ax=axes[1])\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4b8e737",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_carrying_capacities(k_H1_final, k_H2_final, Lx, Ly, time_label=\"final\")\n",
    "plot_carrying_capacities(safe_k_H1_final, safe_k_H2_final, Lx, Ly, time_label=\"final\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d4578c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"k_H1_initial min:\", np.min(safe_k_H1_final))\n",
    "print(\"k_H1_initial max:\", np.max(safe_k_H1_final))\n",
    "\n",
    "print(\"k_H2_initial min:\", np.min(safe_k_H2_final))\n",
    "print(\"k_H2_initial max:\", np.max(safe_k_H2_final))\n",
    "\n",
    "print(\"k_V1_initial min:\", np.min(safe_k_V1_final))\n",
    "print(\"k_V2_initial max:\", np.max(safe_k_V2_final))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51a6e850",
   "metadata": {},
   "outputs": [],
   "source": [
    "H1_all_time = []\n",
    "\n",
    "for y in sol.y.T:  # sol.y.T has shape (Nt, total_state_size)\n",
    "    _, _, H1, _, _ = unflatten_fields(y, Nx, Ny, 5)  # Ensure this returns (Nx, Ny)\n",
    "    H1_all_time.append(H1)\n",
    "\n",
    "H1_all_time = np.stack(H1_all_time, axis=0)  # Final shape: (Nt, Nx, Ny)\n",
    "print(\"H1_all_time shape:\", H1_all_time.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c251ab94",
   "metadata": {},
   "outputs": [],
   "source": [
    "H1_final = H1_all_time[-1]  # Shape: (Nx, Ny)\n",
    "\n",
    "mid_x = Nx // 2\n",
    "H1_left_final = H1_final[mid_x:, :]     # Shape: (Nx//2, Ny)\n",
    "H1_right_final = H1_final[:mid_x, :]    # Shape: (Nx//2, Ny)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22c0cd55",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Left Half\n",
    "plt.figure(figsize=(6, 5))\n",
    "plt.imshow(H1_left_final.T, origin='lower', cmap='viridis', aspect='auto')\n",
    "plt.colorbar(label='H1 Density')\n",
    "plt.title('H1 Density – Left Half at Final Time')\n",
    "plt.xlabel('X (Left Half)')\n",
    "plt.ylabel('Y')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Right Half\n",
    "plt.figure(figsize=(6, 5))\n",
    "plt.imshow(H1_right_final.T, origin='lower', cmap='viridis', aspect='auto')\n",
    "plt.colorbar(label='H1 Density')\n",
    "plt.title('H1 Density – Right Half at Final Time')\n",
    "plt.xlabel('X (Right Half)')\n",
    "plt.ylabel('Y')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f852c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "safe_r_P_means = [np.mean(entry[1]) for entry in logged_data[\"safe_r_P\"]]\n",
    "times = [entry[0] for entry in logged_data[\"safe_r_P\"]]\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(times, safe_r_P_means, marker='o', linestyle='-')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Mean safe_r_P')\n",
    "plt.title('Mean safe_r_P Over Time')\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "263f8130",
   "metadata": {},
   "outputs": [],
   "source": [
    "predation_H2_means = [np.mean(entry[1]) for entry in logged_data[\"predation_H2\"]]\n",
    "times = [entry[0] for entry in logged_data[\"predation_H2\"]]\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(times, predation_H2_means, marker='o', linestyle='-')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Mean safe_r_P')\n",
    "plt.title('Mean safe_r_P Over Time')\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33037897",
   "metadata": {},
   "outputs": [],
   "source": [
    "predation_H1_means = [np.mean(entry[1]) for entry in logged_data[\"predation_H1\"]]\n",
    "times = [entry[0] for entry in logged_data[\"predation_H1\"]]\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(times, predation_H1_means, marker='o', linestyle='-')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Mean safe_r_P')\n",
    "plt.title('Mean safe_r_P Over Time')\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84fb62ff",
   "metadata": {},
   "source": [
    "## Leakage of the wolf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5abe477a",
   "metadata": {},
   "outputs": [],
   "source": [
    "P_edges = [np.mean(P[0, :]) + np.mean(P[-1, :]) + np.mean(P[:, 0]) + np.mean(P[:, -1]) for P in P_over_time]\n",
    "plt.plot(P_edges)\n",
    "plt.title('Average Wolf Density at Edges Over Time')\n",
    "plt.xlabel('Time Step')\n",
    "plt.ylabel('Mean Edge Density')\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ce41cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_P = [np.sum(P) for P in P_over_time]\n",
    "\n",
    "plt.plot(total_P)\n",
    "plt.title('Total Wolf Population Over Time')\n",
    "plt.xlabel('Time Step')\n",
    "plt.ylabel('Total P')\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
